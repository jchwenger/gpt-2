{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 \n",
    "---\n",
    "## Study notebook\n",
    "\n",
    "Mostly TF utils & standard functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape list\n",
    "\n",
    "Why the dynamic thing in the first place? See [this comment](https://stackoverflow.com/a/34082273) It is to deal with the difference with dynamic and static shapes: when data flows through the network on a batch per batch basis, the shapes will be, for instance, [None, x, y, z], and therefore the shape is not defined statically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list_comm(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    print('static:', static)\n",
    "    dynamic = tf.shape(x)\n",
    "    print('dynamic:', dynamic)\n",
    "    for i, s in enumerate(static):\n",
    "        print(s)\n",
    "        print(dynamic[i])\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-10 -21]\n",
      "  [-14   9]\n",
      "  [  1  -8]]\n",
      "\n",
      " [[-26   8]\n",
      "  [  7 -14]\n",
      "  [-33 -21]]\n",
      "\n",
      " [[ 25  14]\n",
      "  [ -5  -8]\n",
      "  [ 48  15]]\n",
      "\n",
      " [[ 13  18]\n",
      "  [-36   8]\n",
      "  [-45   5]]], shape=(4, 3, 2), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.random.normal([4, 3,2], \n",
    "                      mean=0.0, \n",
    "                      stddev=20,\n",
    "                      dtype=tf.float32)\n",
    "print(tf.cast(t1, tf.int16)) # casting to int for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static: [4, 3, 2]\n",
      "dynamic: tf.Tensor([4 3 2], shape=(3,), dtype=int32)\n",
      "4\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "3\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "2\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 3, 2]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_list_comm(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Fun star operator (python)\n",
    "(used e.g. line 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "*start, m = shape_list(t1)\n",
    "print(start)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce_mean, reduce_max \n",
    "\n",
    "Play with this & other shape fluff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.5, shape=(), dtype=float32)\n",
      "tf.Tensor([3. 4.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([1.  2.5 7. ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "xmean = tf.constant([[1., 1.],\n",
    "                     [3.,2.],\n",
    "                     [5., 9.]])\n",
    "print(tf.reduce_mean(xmean)) # A scalar\n",
    "print(tf.reduce_mean(xmean, axis=0)) # 'vertical' mean\n",
    "print(tf.reduce_mean(xmean, axis=1)) # 'horizontal/internal' mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor([5. 9.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([1. 3. 9.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([[5. 9.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [3.]\n",
      " [9.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(xmean))\n",
    "print(tf.reduce_max(xmean, axis=0))\n",
    "print(tf.reduce_max(xmean, axis=-1)) # innermost axis\n",
    "print(tf.reduce_max(xmean, axis=0, keepdims=True))\n",
    "print(tf.reduce_max(xmean, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmean.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmean.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmean.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmean.shape[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=616, shape=(2,), dtype=int32, numpy=array([3, 2], dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(xmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 3.]\n",
      " [2. 5. 9.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor([[1. 1. 3. 2. 5. 9.]], shape=(1, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(xmean, [2,3]))\n",
    "print(tf.reshape(xmean, [1,6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting & merging states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_states(x, n):\n",
    "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
    "    *start, m = shape_list(x)\n",
    "    return tf.reshape(x, start + [n, m//n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitx = tf.get_variable(\"splitx\",\n",
    "                         [2,3,4],\n",
    "                         tf.float32,\n",
    "                         initializer=tf.glorot_uniform_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'splitx:0' shape=(2, 3, 4) dtype=float32, numpy=\n",
       "array([[[ 0.09519899, -0.5179945 ,  0.60571945, -0.61901444],\n",
       "        [ 0.5326501 ,  0.6256759 , -0.21402407, -0.07976532],\n",
       "        [-0.14802265,  0.11726612,  0.35453045,  0.42391026]],\n",
       "\n",
       "       [[ 0.45691597,  0.24667728,  0.04992068, -0.42152926],\n",
       "        [ 0.07240939, -0.40548953,  0.5585022 ,  0.50473773],\n",
       "        [-0.22778407,  0.28633028, -0.44296736, -0.0016287 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "4\n",
      "[2, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "*start, m = shape_list(splitx)\n",
    "n = 2\n",
    "print(start)\n",
    "print(m)\n",
    "print(start + [n, m//n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=799, shape=(2, 3, 2, 2), dtype=float32, numpy=\n",
       "array([[[[ 0.09519899, -0.5179945 ],\n",
       "         [ 0.60571945, -0.61901444]],\n",
       "\n",
       "        [[ 0.5326501 ,  0.6256759 ],\n",
       "         [-0.21402407, -0.07976532]],\n",
       "\n",
       "        [[-0.14802265,  0.11726612],\n",
       "         [ 0.35453045,  0.42391026]]],\n",
       "\n",
       "\n",
       "       [[[ 0.45691597,  0.24667728],\n",
       "         [ 0.04992068, -0.42152926]],\n",
       "\n",
       "        [[ 0.07240939, -0.40548953],\n",
       "         [ 0.5585022 ,  0.50473773]],\n",
       "\n",
       "        [[-0.22778407,  0.28633028],\n",
       "         [-0.44296736, -0.0016287 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitx_states = split_states(splitx, 2)\n",
    "splitx_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_states(x):\n",
    "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
    "    *start, a, b = shape_list(x)\n",
    "    return tf.reshape(x, start + [a*b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=803, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.09519899, -0.5179945 ,  0.60571945, -0.61901444],\n",
       "        [ 0.5326501 ,  0.6256759 , -0.21402407, -0.07976532],\n",
       "        [-0.14802265,  0.11726612,  0.35453045,  0.42391026]],\n",
       "\n",
       "       [[ 0.45691597,  0.24667728,  0.04992068, -0.42152926],\n",
       "        [ 0.07240939, -0.40548953,  0.5585022 ,  0.50473773],\n",
       "        [-0.22778407,  0.28633028, -0.44296736, -0.0016287 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_splitx = merge_states(splitx_states)\n",
    "re_splitx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nprint(*args):\n",
    "    print(*args, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myconvertor(arg):\n",
    "    return tf.convert_to_tensor(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10  2  3], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nprint(myconvertor(tf.constant([10,2,3]))) # tf tensors\n",
    "nprint(myconvertor(2)) # scalars\n",
    "nprint(myconvertor([1,2,3])) # lists\n",
    "nprint(myconvertor((1,2,3))) # tuples\n",
    "nprint(myconvertor([[1,2,3],[4,5,6]])) # more lists\n",
    "nprint(myconvertor(np.array([1,2,3]))) # numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF expand dims\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/expand_dims).\n",
    "\n",
    "\n",
    "> Given a tensor `input`, this operation inserts a dimension of 1 at the dimension index `axis` of `input`'s shape. The dimension index `axis` starts at zero; if you specify a negative number for `axis` it is counted backward from the end.  \n",
    ">\n",
    "> This operation is useful if you want to add a batch dimension to a single element. For example, if you have a single image of shape `[height, width, channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`, which will make the shape `[1, height, width, channels]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 2)\n",
      "[[[-0.4956274   0.49113512]\n",
      "  [-0.41286486  0.35620266]\n",
      "  [-0.4334615   0.15532726]]\n",
      "\n",
      " [[-0.28003323 -0.22134745]\n",
      "  [-0.14616278 -0.09085426]\n",
      "  [-0.46632233  0.31075937]]\n",
      "\n",
      " [[-0.5278535   0.41998708]\n",
      "  [-0.35841405  0.29415405]\n",
      "  [ 0.02429056 -0.39607567]]\n",
      "\n",
      " [[ 0.00269699  0.23218775]\n",
      "  [ 0.5431715   0.40847325]\n",
      "  [-0.31780624  0.08248389]]]\n"
     ]
    }
   ],
   "source": [
    "dms = tf.get_variable('dms', [4,3,2])\n",
    "print(dms.shape)\n",
    "print(dms.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 3, 2)\n",
      "\n",
      "[[[[-0.4956274   0.49113512]\n",
      "   [-0.41286486  0.35620266]\n",
      "   [-0.4334615   0.15532726]]\n",
      "\n",
      "  [[-0.28003323 -0.22134745]\n",
      "   [-0.14616278 -0.09085426]\n",
      "   [-0.46632233  0.31075937]]\n",
      "\n",
      "  [[-0.5278535   0.41998708]\n",
      "   [-0.35841405  0.29415405]\n",
      "   [ 0.02429056 -0.39607567]]\n",
      "\n",
      "  [[ 0.00269699  0.23218775]\n",
      "   [ 0.5431715   0.40847325]\n",
      "   [-0.31780624  0.08248389]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nprint(tf.expand_dims(dms, 0).shape)\n",
    "nprint(tf.expand_dims(dms, 0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 3, 2)\n",
      "\n",
      "[[[[-0.4956274   0.49113512]\n",
      "   [-0.41286486  0.35620266]\n",
      "   [-0.4334615   0.15532726]]]\n",
      "\n",
      "\n",
      " [[[-0.28003323 -0.22134745]\n",
      "   [-0.14616278 -0.09085426]\n",
      "   [-0.46632233  0.31075937]]]\n",
      "\n",
      "\n",
      " [[[-0.5278535   0.41998708]\n",
      "   [-0.35841405  0.29415405]\n",
      "   [ 0.02429056 -0.39607567]]]\n",
      "\n",
      "\n",
      " [[[ 0.00269699  0.23218775]\n",
      "   [ 0.5431715   0.40847325]\n",
      "   [-0.31780624  0.08248389]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nprint(tf.expand_dims(dms, 1).shape)\n",
    "nprint(tf.expand_dims(dms, 1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 1, 2)\n",
      "\n",
      "[[[[-0.4956274   0.49113512]]\n",
      "\n",
      "  [[-0.41286486  0.35620266]]\n",
      "\n",
      "  [[-0.4334615   0.15532726]]]\n",
      "\n",
      "\n",
      " [[[-0.28003323 -0.22134745]]\n",
      "\n",
      "  [[-0.14616278 -0.09085426]]\n",
      "\n",
      "  [[-0.46632233  0.31075937]]]\n",
      "\n",
      "\n",
      " [[[-0.5278535   0.41998708]]\n",
      "\n",
      "  [[-0.35841405  0.29415405]]\n",
      "\n",
      "  [[ 0.02429056 -0.39607567]]]\n",
      "\n",
      "\n",
      " [[[ 0.00269699  0.23218775]]\n",
      "\n",
      "  [[ 0.5431715   0.40847325]]\n",
      "\n",
      "  [[-0.31780624  0.08248389]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nprint(tf.expand_dims(dms, 2).shape)\n",
    "nprint(tf.expand_dims(dms, 2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 2, 1)\n",
      "\n",
      "[[[[-0.4956274 ]\n",
      "   [ 0.49113512]]\n",
      "\n",
      "  [[-0.41286486]\n",
      "   [ 0.35620266]]\n",
      "\n",
      "  [[-0.4334615 ]\n",
      "   [ 0.15532726]]]\n",
      "\n",
      "\n",
      " [[[-0.28003323]\n",
      "   [-0.22134745]]\n",
      "\n",
      "  [[-0.14616278]\n",
      "   [-0.09085426]]\n",
      "\n",
      "  [[-0.46632233]\n",
      "   [ 0.31075937]]]\n",
      "\n",
      "\n",
      " [[[-0.5278535 ]\n",
      "   [ 0.41998708]]\n",
      "\n",
      "  [[-0.35841405]\n",
      "   [ 0.29415405]]\n",
      "\n",
      "  [[ 0.02429056]\n",
      "   [-0.39607567]]]\n",
      "\n",
      "\n",
      " [[[ 0.00269699]\n",
      "   [ 0.23218775]]\n",
      "\n",
      "  [[ 0.5431715 ]\n",
      "   [ 0.40847325]]\n",
      "\n",
      "  [[-0.31780624]\n",
      "   [ 0.08248389]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nprint(tf.expand_dims(dms, 3).shape)\n",
    "nprint(tf.expand_dims(dms, 3).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Tile\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/tile).\n",
    "\n",
    "\n",
    "> `tf.tile(input, multiples, name=None)`\n",
    "\n",
    "> This operation creates a new tensor by replicating `input multiples` times. The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements, and the values of `input` are replicated `multiples[i]` times along the 'i'th dimension. For example, tiling `[a b c d]` by `[2]` produces `[a b c d a b c d]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 0 1 2 3 4]\n",
      "\n",
      "------------------------------\n",
      "[[0 1 2 0 1 2]\n",
      " [3 4 5 3 4 5]]\n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "[[0 1 2 0 1 2]\n",
      " [3 4 5 3 4 5]\n",
      " [0 1 2 0 1 2]\n",
      " [3 4 5 3 4 5]]\n",
      "\n",
      "------------------------------\n",
      "[[[0 1 0 1]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[3 4 3 4]\n",
      "  [4 5 4 5]]]\n",
      "\n",
      "[[[0 1]\n",
      "  [1 2]\n",
      "  [0 1]\n",
      "  [1 2]]\n",
      "\n",
      " [[3 4]\n",
      "  [4 5]\n",
      "  [3 4]\n",
      "  [4 5]]]\n",
      "\n",
      "[[[0 1 0 1]\n",
      "  [1 2 1 2]\n",
      "  [0 1 0 1]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[3 4 3 4]\n",
      "  [4 5 4 5]\n",
      "  [3 4 3 4]\n",
      "  [4 5 4 5]]]\n",
      "\n",
      "[[[0 1 0 1]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[3 4 3 4]\n",
      "  [4 5 4 5]]\n",
      "\n",
      " [[0 1 0 1]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[3 4 3 4]\n",
      "  [4 5 4 5]]]\n",
      "\n",
      "[[[0 1]\n",
      "  [1 2]\n",
      "  [0 1]\n",
      "  [1 2]]\n",
      "\n",
      " [[3 4]\n",
      "  [4 5]\n",
      "  [3 4]\n",
      "  [4 5]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 2]\n",
      "  [0 1]\n",
      "  [1 2]]\n",
      "\n",
      " [[3 4]\n",
      "  [4 5]\n",
      "  [3 4]\n",
      "  [4 5]]]\n",
      "\n",
      "[[[0 1 0 1]\n",
      "  [1 2 1 2]\n",
      "  [0 1 0 1]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[3 4 3 4]\n",
      "  [4 5 4 5]\n",
      "  [3 4 3 4]\n",
      "  [4 5 4 5]]\n",
      "\n",
      " [[0 1 0 1]\n",
      "  [1 2 1 2]\n",
      "  [0 1 0 1]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[3 4 3 4]\n",
      "  [4 5 4 5]\n",
      "  [3 4 3 4]\n",
      "  [4 5 4 5]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = tf.constant([0,1,2,3,4])\n",
    "nprint(tf.tile(tt, [2]).numpy())\n",
    "print('-'*30)\n",
    "tt = tf.constant([[0,1,2],[3,4,5]])\n",
    "nprint(tf.tile(tt, [1, 2]).numpy())\n",
    "nprint(tf.tile(tt, [2, 1]).numpy())\n",
    "nprint(tf.tile(tt, [2, 2]).numpy())\n",
    "print('-'*30)\n",
    "tt = tf.constant([[[0,1],[1,2]],[[3,4],[4,5]]])\n",
    "nprint(tf.tile(tt, [1, 1, 2]).numpy())\n",
    "nprint(tf.tile(tt, [1, 2, 1]).numpy())\n",
    "nprint(tf.tile(tt, [1, 2, 2]).numpy())\n",
    "nprint(tf.tile(tt, [2, 1, 2]).numpy())\n",
    "nprint(tf.tile(tt, [2, 2, 1]).numpy())\n",
    "nprint(tf.tile(tt, [2, 2, 2]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example from GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0839658   0.36698222  0.13701785]\n",
      " [-0.8101032   0.7864109  -1.0563312 ]]\n"
     ]
    }
   ],
   "source": [
    "# tl = tf.get_variable('tl', [2])\n",
    "tl = tf.get_variable('tl', [2,3])\n",
    "print(tl.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "ndims = tl.shape.ndims\n",
    "print(ndims)\n",
    "print([size] + [1]*ndims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you need that `expand_dims` thingy? In order to stack your 2d vector into a 3d one. To keep it 2d and shove the copies/tiles inside, do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0839658   0.36698222  0.13701785]\n",
      " [-0.8101032   0.7864109  -1.0563312 ]\n",
      " [ 1.0839658   0.36698222  0.13701785]\n",
      " [-0.8101032   0.7864109  -1.0563312 ]\n",
      " [ 1.0839658   0.36698222  0.13701785]\n",
      " [-0.8101032   0.7864109  -1.0563312 ]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.tile(tl, [size] + [1]*(ndims-1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n",
      "[[[ 1.0839658   0.36698222  0.13701785]\n",
      "  [-0.8101032   0.7864109  -1.0563312 ]]\n",
      "\n",
      " [[ 1.0839658   0.36698222  0.13701785]\n",
      "  [-0.8101032   0.7864109  -1.0563312 ]]\n",
      "\n",
      " [[ 1.0839658   0.36698222  0.13701785]\n",
      "  [-0.8101032   0.7864109  -1.0563312 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.tile(tf.expand_dims(tl, axis=0), [size] + [1]*ndims).shape)\n",
    "print(tf.tile(tf.expand_dims(tl, axis=0), [size] + [1]*ndims).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The actual function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tile(value, size):\n",
    "    \"\"\"Add a new axis of given size.\"\"\"\n",
    "    value = tf.convert_to_tensor(value, name='value')\n",
    "    ndims = value.shape.ndims\n",
    "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "------------------------------\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]]]\n",
      "\n",
      "------------------------------\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expt = tf.constant([[1,2,3],[4,5,6]])\n",
    "nprint(expt.numpy())\n",
    "print('-'*30)\n",
    "nprint(expand_tile(expt, 2).numpy())\n",
    "print('-'*30)\n",
    "nprint(expand_tile(expt, 4).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
