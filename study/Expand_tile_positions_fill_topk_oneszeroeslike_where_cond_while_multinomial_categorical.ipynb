{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nprint(*args):\n",
    "    print(*args, end='\\n\\n-----------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Expand Tile, Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Size` is the batch size > will produce as many tilings (copies) of the vector as there are batches. E.g. `[1,2,3]` with three batches: `[[1,2,3],[1,2,3],[1,2,3]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tile(value, size):\n",
    "    \"\"\"\n",
    "    Tile (duplicate) tensor size times: from [x,y] to [[x,y],[x,y] .. size times .. [x,y]]\n",
    "    Constructed so as to be able to take lists, tuples, etc. as input.\n",
    "    \"\"\"\n",
    "    value = tf.convert_to_tensor(value, name='value')\n",
    "    ndims = value.shape.ndims\n",
    "\n",
    "    # expand [x,y] to [[x,y]], then tile [size] times according to the outer dim\n",
    "    # ([size] + [1]*ndims turning into e.g. [3,1,1])\n",
    "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[0 1]]\n",
      "[[0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(expand_tile([0,1], 0).numpy())\n",
    "print(expand_tile([0,1], 1).numpy())\n",
    "print(expand_tile([0,1], 2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positions_for(tokens, past_length):\n",
    "    batch_size = tf.shape(tokens)[0]\n",
    "    nsteps = tf.shape(tokens)[1]\n",
    "    \n",
    "    print('batch_size:', batch_size.numpy(), \n",
    "          '| nsteps:', nsteps.numpy(), \n",
    "          '| tf.range(nsteps):', tf.range(nsteps).numpy(), \n",
    "          '| past length:', past_length if type(past_length) == int else past_length.numpy(),\n",
    "          '\\n\\npast length + range:\\n', (past_length + tf.range(nsteps)).numpy(),\n",
    "          '\\n\\nresult vector:')\n",
    "    \n",
    "    return expand_tile(past_length + tf.range(nsteps), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8 -1  0]\n",
      "  [ 7  1 -6]]\n",
      "\n",
      " [[ 2 -1 -2]\n",
      "  [ 8  2  8]]\n",
      "\n",
      " [[ 9  6  3]\n",
      "  [-7  0  4]]\n",
      "\n",
      " [[ 5  2  4]\n",
      "  [-9  7 -3]]\n",
      "\n",
      " [[-1 -2  6]\n",
      "  [-3 -8 -6]]]\n",
      "(5, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "tkns = tf.cast(20*tf.get_variable('tkns', [5,2,3]),\n",
    "               tf.int32)\n",
    "print(tkns.numpy())\n",
    "print(tkns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8 -1  0]\n",
      " [ 2 -1 -2]\n",
      " [ 9  6  3]\n",
      " [ 5  2  4]\n",
      " [-1 -2  6]]\n",
      "\n",
      "-----------------\n",
      "[[ 7  1 -6]\n",
      " [ 8  2  8]\n",
      " [-7  0  4]\n",
      " [-9  7 -3]\n",
      " [-3 -8 -6]]\n",
      "\n",
      "-----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nprint(unst.numpy()) for unst in tf.unstack(tkns, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here using `tf.shape(tkns)` as it is in the model, to show the results:  \n",
    "```\n",
    "past_length = 0 if past is None else tf.shape(past)[-2]\n",
    "```\n",
    "The value of `past_length` gets broadcast into the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 3 | nsteps: 5 | tf.range(nsteps): [0 1 2 3 4] | past length: 0 \n",
      "\n",
      "past length + range:\n",
      " [0 1 2 3 4] \n",
      "\n",
      "result vector:\n",
      "[[0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]]\n",
      "\n",
      "-----------------\n",
      "batch_size: 3 | nsteps: 5 | tf.range(nsteps): [0 1 2 3 4] | past length: 3 \n",
      "\n",
      "past length + range:\n",
      " [3 4 5 6 7] \n",
      "\n",
      "result vector:\n",
      "[[3 4 5 6 7]\n",
      " [3 4 5 6 7]\n",
      " [3 4 5 6 7]]\n",
      "\n",
      "-----------------\n",
      "batch_size: 3 | nsteps: 5 | tf.range(nsteps): [0 1 2 3 4] | past length: 5 \n",
      "\n",
      "past length + range:\n",
      " [5 6 7 8 9] \n",
      "\n",
      "result vector:\n",
      "[[5 6 7 8 9]\n",
      " [5 6 7 8 9]\n",
      " [5 6 7 8 9]]\n",
      "\n",
      "-----------------\n",
      "batch_size: 3 | nsteps: 5 | tf.range(nsteps): [0 1 2 3 4] | past length: 1 \n",
      "\n",
      "past length + range:\n",
      " [1 2 3 4 5] \n",
      "\n",
      "result vector:\n",
      "[[1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]]\n",
      "\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "nprint(positions_for(tkns, 0).numpy())\n",
    "nprint(positions_for(tkns, tf.shape(tkns)[0]).numpy())\n",
    "nprint(positions_for(tkns, tf.shape(tkns)[1]).numpy())\n",
    "nprint(positions_for(tkns, tf.shape(tkns)[2]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Fill\n",
    "\n",
    "Nice and easy, fill a tensor of a certain shape with a value. \n",
    "\n",
    "Reference [here](https://www.tensorflow.org/api_docs/python/tf/fill):\n",
    "\n",
    "`tf.fill` differs from `tf.constant` in a few ways:\n",
    "- `tf.fill` only supports scalar contents, whereas `tf.constant` supports Tensor values.\n",
    "- `tf.fill` creates an Op in the computation graph that constructs the actual Tensor value at runtime. This is in contrast to `tf.constant` which embeds the entire Tensor into the graph with a `Const` node.\n",
    "- Because `tf.fill` evaluates at graph runtime, it supports dynamic shapes based on other runtime Tensors, unlike `tf.constant.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4120, shape=(2, 3), dtype=int32, numpy=\n",
       "array([[9, 9, 9],\n",
       "       [9, 9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([2,3], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b'blah']\n",
      " [b'blah']\n",
      " [b'blah']], shape=(3, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "print(tf.fill([batch_size, 1], 'blah'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "TF nn.top_k / math.top_k\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/math/top_k).\n",
    "\n",
    "> Finds values and indices of the `k` largest entries for the last dimension.\n",
    "\n",
    "(k=1: only the max, k=2: the 2 largest ones, etc.)\n",
    "\n",
    "(For the opposite, see [this answer on the Stack](https://stackoverflow.com/a/44553559): `-tf.nn.top_k(-A)` will do the same as `tf.negative(tf.nn.top_k(tf.negative(A)))`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "[[3 2]\n",
      " [6 5]\n",
      " [9 8]]\n",
      "\n",
      "[[2 1]\n",
      " [2 1]\n",
      " [2 1]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = tf.constant([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(topk.numpy(),end='\\n\\n')\n",
    "[print(tp.numpy(),end='\\n\\n') for tp in tf.nn.top_k(topk, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always goes to the last dimension (obviously) to fetch the values, and keeps dimensions intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]]\n",
      "\n",
      "[[[ 3]\n",
      "  [ 7]\n",
      "  [11]]\n",
      "\n",
      " [[15]\n",
      "  [19]\n",
      "  [23]]]\n",
      "\n",
      "[[[3]\n",
      "  [3]\n",
      "  [3]]\n",
      "\n",
      " [[3]\n",
      "  [3]\n",
      "  [3]]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = tf.constant(np.arange(24), shape=[2,3,4])\n",
    "print(topk.numpy(),end='\\n\\n')\n",
    "[print(tp.numpy(),end='\\n\\n') for tp in tf.nn.top_k(topk, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to the negative (minimum values)(as well as upping my game tensorwise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3]\n",
      "   [ 4  5  6  7]\n",
      "   [ 8  9 10 11]]\n",
      "\n",
      "  [[12 13 14 15]\n",
      "   [16 17 18 19]\n",
      "   [20 21 22 23]]]\n",
      "\n",
      "\n",
      " [[[24 25 26 27]\n",
      "   [28 29 30 31]\n",
      "   [32 33 34 35]]\n",
      "\n",
      "  [[36 37 38 39]\n",
      "   [40 41 42 43]\n",
      "   [44 45 46 47]]]]\n",
      "\n",
      "[[[[ 0]\n",
      "   [ 4]\n",
      "   [ 8]]\n",
      "\n",
      "  [[12]\n",
      "   [16]\n",
      "   [20]]]\n",
      "\n",
      "\n",
      " [[[24]\n",
      "   [28]\n",
      "   [32]]\n",
      "\n",
      "  [[36]\n",
      "   [40]\n",
      "   [44]]]]\n",
      "\n",
      "[[[[0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]]]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = tf.constant(np.arange(48), shape=[2,2,3,4])\n",
    "print(topk.numpy(),end='\\n\\n')\n",
    "[print(-tp.numpy(),end='\\n\\n') for tp in tf.nn.top_k(-topk, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8 -1  0]\n",
      "  [ 7  1 -6]]\n",
      "\n",
      " [[ 2 -1 -2]\n",
      "  [ 8  2  8]]\n",
      "\n",
      " [[ 9  6  3]\n",
      "  [-7  0  4]]\n",
      "\n",
      " [[ 5  2  4]\n",
      "  [-9  7 -3]]\n",
      "\n",
      " [[-1 -2  6]\n",
      "  [-3 -8 -6]]]\n"
     ]
    }
   ],
   "source": [
    "print(tkns.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 6]]\n",
      "\n",
      " [[-2]]\n",
      "\n",
      " [[ 7]]\n",
      "\n",
      " [[ 9]]\n",
      "\n",
      " [[ 8]]]\n"
     ]
    }
   ],
   "source": [
    "min_values, _ = tf.nn.top_k(-tkns, k=1)\n",
    "print(min_values[:,-1, None].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0]\n",
      "  [ 7]]\n",
      "\n",
      " [[ 2]\n",
      "  [ 8]]\n",
      "\n",
      " [[ 9]\n",
      "  [ 4]]\n",
      "\n",
      " [[ 5]\n",
      "  [ 7]]\n",
      "\n",
      " [[ 6]\n",
      "  [-3]]]\n",
      "[[[ 7]]\n",
      "\n",
      " [[ 8]]\n",
      "\n",
      " [[ 4]]\n",
      "\n",
      " [[ 7]]\n",
      "\n",
      " [[-3]]]\n"
     ]
    }
   ],
   "source": [
    "values, _ = tf.nn.top_k(tkns, k=1) # max k for each tensor in last dim\n",
    "print(values.numpy())\n",
    "min_values = values[:, -1, tf.newaxis]\n",
    "print(min_values.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Where\n",
    "\n",
    "Reference [here](https://www.tensorflow.org/api_docs/python/tf/where).\n",
    "\n",
    "Return the elements, either from x or y, depending on the condition.\n",
    "\n",
    "### Ones/Zeros like\n",
    "\n",
    "Reference [here](https://www.tensorflow.org/api_docs/python/tf/ones_like) and [here](https://www.tensorflow.org/api_docs/python/tf/zeros_like).\n",
    "\n",
    "Return tensor filled with ones/zeros of the shape of tensor input.\n",
    "\n",
    "### TF Cond\n",
    "\n",
    "Reference [here]().\n",
    "\n",
    "Implements conditionals in graphs (hell). Will be simplified in TF2.\n",
    "\n",
    "Note: in order to pass arguments to the called functions, you need to build them as lambdas, as explained [on the Stack](https://stackoverflow.com/a/39573566). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 5 0 0 0]\n",
      "[1 2 3 5 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "whr = tf.constant([1,2,3,5,6,7,8])\n",
    "\n",
    "def give_ones(whr):\n",
    "    return tf.where(whr < 6,\n",
    "                    whr,\n",
    "                    tf.ones_like(whr))\n",
    "    \n",
    "def give_zeros(whr):\n",
    "        return tf.where(whr < 6,\n",
    "                    whr,\n",
    "                    tf.zeros_like(whr))\n",
    "        \n",
    "# the zeros return\n",
    "print(tf.cond(whr.shape == 6,\n",
    "       lambda: give_ones(whr), \n",
    "       lambda: give_zeros(whr)).numpy())\n",
    "\n",
    "# the ones return\n",
    "print(tf.cond(whr.shape == 7,\n",
    "       lambda: give_ones(whr), \n",
    "       lambda: give_zeros(whr)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF While loop\n",
    "\n",
    "Reference [here](https://www.tensorflow.org/api_docs/python/tf/while_loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4 -2 6\n",
      "\n",
      "-8 -4 0\n",
      "\n",
      "-4 4 -12\n",
      "\n",
      "4 20 -12\n",
      "\n",
      "-4 28 12\n",
      "\n",
      "-44 20 36\n",
      "\n",
      "-100 28 12\n",
      "\n",
      "-140 116 -60\n",
      "\n",
      "-196 316 -84\n",
      "\n",
      "-428 596 36\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-428, 596, 36]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cond(*args):\n",
    "    return True\n",
    "\n",
    "def body(x, y, z):\n",
    "    print(x-y-z, -x+y-z, x+y+z)\n",
    "    print()\n",
    "    return [x-y-z, -x+y-z, x+y+z] # needs to return the same shape as its input, \n",
    "                                  # as these will be fed in the next iteration\n",
    "tf.while_loop(\n",
    "    cond=cond,\n",
    "    body=body,\n",
    "    loop_vars=[1,2,3],\n",
    "    back_prop=False,\n",
    "    maximum_iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Multinomial/Categorical\n",
    "\n",
    "[Multinomial](https://www.tensorflow.org/api_docs/python/tf/random/multinomial): Draws samples from a multinomial distribution. (says it's deprecated but is the only one working in tf 1.12...).  \n",
    "[Categorical](https://www.tensorflow.org/api_docs/python/tf/random/categorical): Draws samples from a categorical distribution.\n",
    "\n",
    "Returns the index of the sample (<-> its class, in our case which token/character has been taken)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "[[ 1.6614330e+00  1.8465611e+00  1.2419925e+00  1.8122669e+00\n",
      "   1.8083012e+00  1.3323863e+00  2.1042039e+00  2.0606184e+00\n",
      "   1.2898836e+00  1.2235551e+00  1.3590236e+00  2.0356238e+00\n",
      "   1.9787459e+00  1.5589540e+00  1.8931404e+00  1.2853543e+00\n",
      "   1.5432556e+00  1.2538865e+00  1.6112630e+00  1.6507741e+00\n",
      "  -1.2851691e-02  1.9858840e+00  1.6952589e+00  2.1319540e+00\n",
      "  -6.1222482e-01  1.9517276e+00  1.6481156e+00  1.3833491e+00\n",
      "   1.3723737e+00  9.0254259e-01  1.5697762e+00  2.0009382e+00\n",
      "  -1.6136631e-01  7.5235856e-01  1.3757418e+00  1.6696959e+00\n",
      "   1.7772396e+00  1.2080791e+00  1.7911468e+00  1.9001979e+00\n",
      "   1.2330620e+00  1.7922444e+00  1.7293684e+00  1.8890799e+00\n",
      "   2.2396121e+00  1.7890160e+00  2.1262302e+00  1.9232343e+00\n",
      "   1.5086039e+00  1.4677848e+00  8.3263904e-01  1.3818003e+00\n",
      "   6.6127515e-01  2.0995927e+00  1.3393655e+00  1.6124418e+00\n",
      "   1.4841000e+00  1.4615728e+00  1.9389315e+00  1.1315494e+00\n",
      "   1.7599026e+00  1.3196810e+00  1.6478530e+00 -2.3025850e+01\n",
      "   1.0293776e+00  1.4163375e+00  1.5317264e+00  1.6059334e+00\n",
      "   1.3920927e+00  1.0110712e+00  1.6552709e+00  1.3586478e+00\n",
      "   1.4546504e+00  3.0511481e-01  1.5091615e+00  7.5173998e-01\n",
      "   1.2898374e+00  1.6489002e+00  2.0243597e+00  1.5296884e+00\n",
      "   1.5687461e+00  1.3238301e+00  1.2981869e+00  1.8375287e+00\n",
      "   1.6437519e+00  2.1796799e+00  1.6561708e+00  1.2326432e+00\n",
      "   7.4433815e-01  1.2941991e+00  1.5963389e+00  1.9064109e+00\n",
      "   1.7076385e+00  1.5115298e+00  9.4978809e-01  1.3541493e+00\n",
      "   1.4730814e+00  1.8677623e+00  7.9261130e-01  4.9912125e-01]]\n"
     ]
    }
   ],
   "source": [
    "tflg = tf.random.normal([1,100], mean=0.0, stddev=2) \n",
    "tflg -= tf.reduce_min(tflg)\n",
    "tflg += 1e-10\n",
    "tflg = tf.log(tflg)\n",
    "print(tflg.shape)\n",
    "print(tflg.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.multinomial( # same as random.multinomial\n",
    "        logits=tflg, \n",
    "        num_samples=1).numpy(), \n",
    "      end='\\n\\n') \n",
    "# print(samples = tf.random.categorical(tf.log([[10., 10.]]), 5), end='\\n\\n') # ain't working (will in more recent versions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
