{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 \n",
    "---\n",
    "## TF Transpose, Stack, Unstack, Split\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/transpose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition means the dimensions of the matrix will be swapped: for a matrix of `[5,2]`, 5 rows of 2 numbers, the transposition will be 2 rows of 5 numbers. The `perm` parameter allows one to place the specific dimensions in the final matrix. A perm of `[1,0]` means then \"put the dimension 1 (the second one) in the place of the first, and dimension 0 in the place of the second (swap them)\". This becomes more straightforward when more dimensions are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "\n",
      "[[0 2 4 6 8]\n",
      " [1 3 5 7 9]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.reshape(tf.constant(np.arange(10)), [5,2])\n",
    "print(x.numpy(), end='\\n\\n')\n",
    "print(tf.transpose(x).numpy(), end='\\n\\n')\n",
    "# print(tf.transpose(x, perm=[1,0]).numpy(), end='\\n\\n') # identical to the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A variable, shape: five (groups) of two (groups) of three (numbers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.cast(\n",
    "            20*tf.get_variable('x',[5, 2, 3], \n",
    "                            dtype=tf.float32), \n",
    "            tf.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8 -1  2]\n",
      "  [ 0  7 -2]]\n",
      "\n",
      " [[ 0  0  4]\n",
      "  [-1 -4 -5]]\n",
      "\n",
      " [[-8  2 -3]\n",
      "  [ 1  9  9]]\n",
      "\n",
      " [[ 8  7  8]\n",
      "  [-4 -2  4]]\n",
      "\n",
      " [[ 8  3  6]\n",
      "  [ 4  6 -5]]]\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing the last two dimensions mean the inner matrices are switched from horizontal to vertical (or vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8  0]\n",
      "  [-1  7]\n",
      "  [ 2 -2]]\n",
      "\n",
      " [[ 0 -1]\n",
      "  [ 0 -4]\n",
      "  [ 4 -5]]\n",
      "\n",
      " [[-8  1]\n",
      "  [ 2  9]\n",
      "  [-3  9]]\n",
      "\n",
      " [[ 8 -4]\n",
      "  [ 7 -2]\n",
      "  [ 8  4]]\n",
      "\n",
      " [[ 8  4]\n",
      "  [ 3  6]\n",
      "  [ 6 -5]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(x, perm=[0, 2, 1]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another one, the original matrix becomes a 2 (dimension 1) of 3 (dimension 2) of 5 (dimension 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8  0 -8  8  8]\n",
      "  [-1  0  2  7  3]\n",
      "  [ 2  4 -3  8  6]]\n",
      "\n",
      " [[ 0 -1  1 -4  4]\n",
      "  [ 7 -4  9 -2  6]\n",
      "  [-2 -5  9  4 -5]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(x, perm=[1,2,0]).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the last two dimensions are swapped, the following is the close/inner transpose of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8 -1  2]\n",
      "  [ 0  0  4]\n",
      "  [-8  2 -3]\n",
      "  [ 8  7  8]\n",
      "  [ 8  3  6]]\n",
      "\n",
      " [[ 0  7 -2]\n",
      "  [-1 -4 -5]\n",
      "  [ 1  9  9]\n",
      "  [-4 -2  4]\n",
      "  [ 4  6 -5]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(x, perm=[1,0,2]).numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8  0 -8  8  8]\n",
      "  [ 0 -1  1 -4  4]]\n",
      "\n",
      " [[-1  0  2  7  3]\n",
      "  [ 7 -4  9 -2  6]]\n",
      "\n",
      " [[ 2  4 -3  8  6]\n",
      "  [-2 -5  9  4 -5]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(x).numpy())\n",
    "# print(tf.transpose(x, perm=[2, 1, 0]).numpy()) # same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-8  0]\n",
      "  [ 0 -1]\n",
      "  [-8  1]\n",
      "  [ 8 -4]\n",
      "  [ 8  4]]\n",
      "\n",
      " [[-1  7]\n",
      "  [ 0 -4]\n",
      "  [ 2  9]\n",
      "  [ 7 -2]\n",
      "  [ 3  6]]\n",
      "\n",
      " [[ 2 -2]\n",
      "  [ 4 -5]\n",
      "  [-3  9]\n",
      "  [ 8  4]\n",
      "  [ 6 -5]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(x, perm=[2, 0, 1]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TF Stack, Unstack\n",
    "\n",
    "Packing and unpacking tensors.\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/stack) and [here](https://www.tensorflow.org/api_docs/python/tf/unstack).\n",
    "\n",
    "> If `axis == 0` then the i'th tensor in `output` is the slice `value[i, :, :, :]` and each tensor in `output` will have shape `(B, C, D)`. (Note that the dimension unpacked along is gone, unlike `split`).  \n",
    "> If `axis == 1` then the i'th tensor in `output` is the slice `value[:, i, :, :]` and each tensor in `output` will have shape `(A, C, D)`. Etc.\n",
    "\n",
    "Simple case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[3 4 5]\n",
      "[6 7 8]\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.constant(np.arange(0,3), dtype=tf.int32)\n",
    "y2 = tf.constant(np.arange(3,6), dtype=tf.int32)\n",
    "y3 = tf.constant(np.arange(6,9), dtype=tf.int32)\n",
    "print(y1.numpy(), y2.numpy(), y3.numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "y = tf.stack([y1,y2,y3])\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[3 4 5]\n",
      "[6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for unst in tf.unstack(y):\n",
    "    print(unst.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]]\n"
     ]
    }
   ],
   "source": [
    "y = tf.stack([y1,y2,y3], axis=1)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 6]\n",
      "[1 4 7]\n",
      "[2 5 8]\n"
     ]
    }
   ],
   "source": [
    "for unst in tf.unstack(y):\n",
    "    print(unst.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy build-up of new axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 3 6]\n",
      "  [1 4 7]\n",
      "  [2 5 8]]\n",
      "\n",
      " [[0 3 6]\n",
      "  [1 4 7]\n",
      "  [2 5 8]]]\n"
     ]
    }
   ],
   "source": [
    "yy = tf.stack([y,y])\n",
    "print(yy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example (practice with axis=0, 1, 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "\n",
      "(2, 2)\n",
      "[[0 3]\n",
      " [0 3]]\n",
      "\n",
      "(2, 2)\n",
      "[[1 4]\n",
      " [1 4]]\n",
      "\n",
      "(2, 2)\n",
      "[[2 5]\n",
      " [2 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "axis=2\n",
    "cnst = tf.constant([[[0,1,2],[3,4,5]],[[0,1,2],[3,4,5]]])\n",
    "print(cnst.shape)\n",
    "print()\n",
    "for unst in tf.unstack(cnst, axis=axis):\n",
    "    print(unst.shape)\n",
    "    print(unst.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  6  1 -4  0]\n",
      "   [ 0 -4 -5 -1 -5]\n",
      "   [ 6 -6 -5  0 -2]\n",
      "   [ 6 -1  2 -6 -3]]\n",
      "\n",
      "  [[-1  3  2 -2  4]\n",
      "   [ 4 -1  3  4  5]\n",
      "   [ 4 -5  4  0  0]\n",
      "   [-3 -4 -3  3  3]]\n",
      "\n",
      "  [[ 0  4 -3 -4  6]\n",
      "   [-5  4 -5 -5  4]\n",
      "   [ 5 -4  1 -5 -2]\n",
      "   [-2 -4 -4 -5 -4]]]\n",
      "\n",
      "\n",
      " [[[ 4  0  2  4  5]\n",
      "   [ 4 -5  1  4  1]\n",
      "   [-5 -1 -1 -4  3]\n",
      "   [-1  3  0 -6  2]]\n",
      "\n",
      "  [[ 0  5  5 -4 -1]\n",
      "   [ 1  2  1  1  3]\n",
      "   [ 3 -6  1  6 -5]\n",
      "   [ 6  5 -5 -3  2]]\n",
      "\n",
      "  [[ 5 -4 -5 -4 -3]\n",
      "   [ 6  5  3 -6  3]\n",
      "   [ 2 -4  0  6  3]\n",
      "   [-1  1 -5  2  1]]]]\n"
     ]
    }
   ],
   "source": [
    "z = tf.cast(tf.get_variable(name='x',shape=[2,3,4,5])*20, dtype=tf.int32)\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  6  1 -4  0]\n",
      "  [ 0 -4 -5 -1 -5]\n",
      "  [ 6 -6 -5  0 -2]\n",
      "  [ 6 -1  2 -6 -3]]\n",
      "\n",
      " [[-1  3  2 -2  4]\n",
      "  [ 4 -1  3  4  5]\n",
      "  [ 4 -5  4  0  0]\n",
      "  [-3 -4 -3  3  3]]\n",
      "\n",
      " [[ 0  4 -3 -4  6]\n",
      "  [-5  4 -5 -5  4]\n",
      "  [ 5 -4  1 -5 -2]\n",
      "  [-2 -4 -4 -5 -4]]]\n",
      "----------\n",
      "[[[ 4  0  2  4  5]\n",
      "  [ 4 -5  1  4  1]\n",
      "  [-5 -1 -1 -4  3]\n",
      "  [-1  3  0 -6  2]]\n",
      "\n",
      " [[ 0  5  5 -4 -1]\n",
      "  [ 1  2  1  1  3]\n",
      "  [ 3 -6  1  6 -5]\n",
      "  [ 6  5 -5 -3  2]]\n",
      "\n",
      " [[ 5 -4 -5 -4 -3]\n",
      "  [ 6  5  3 -6  3]\n",
      "  [ 2 -4  0  6  3]\n",
      "  [-1  1 -5  2  1]]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for unst in tf.unstack(z): # splits through the outer dimension > two tensors\n",
    "    print(unst.numpy(), end='\\n----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  6  1 -4  0]\n",
      "  [ 0 -4 -5 -1 -5]\n",
      "  [ 6 -6 -5  0 -2]\n",
      "  [ 6 -1  2 -6 -3]]\n",
      "\n",
      " [[ 4  0  2  4  5]\n",
      "  [ 4 -5  1  4  1]\n",
      "  [-5 -1 -1 -4  3]\n",
      "  [-1  3  0 -6  2]]]\n",
      "----------\n",
      "[[[-1  3  2 -2  4]\n",
      "  [ 4 -1  3  4  5]\n",
      "  [ 4 -5  4  0  0]\n",
      "  [-3 -4 -3  3  3]]\n",
      "\n",
      " [[ 0  5  5 -4 -1]\n",
      "  [ 1  2  1  1  3]\n",
      "  [ 3 -6  1  6 -5]\n",
      "  [ 6  5 -5 -3  2]]]\n",
      "----------\n",
      "[[[ 0  4 -3 -4  6]\n",
      "  [-5  4 -5 -5  4]\n",
      "  [ 5 -4  1 -5 -2]\n",
      "  [-2 -4 -4 -5 -4]]\n",
      "\n",
      " [[ 5 -4 -5 -4 -3]\n",
      "  [ 6  5  3 -6  3]\n",
      "  [ 2 -4  0  6  3]\n",
      "  [-1  1 -5  2  1]]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for unst in tf.unstack(z, axis=1):\n",
    "    print(unst.numpy(), end='\\n----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  6  1 -4  0]\n",
      "   [ 0 -4 -5 -1 -5]\n",
      "   [ 6 -6 -5  0 -2]\n",
      "   [ 6 -1  2 -6 -3]]\n",
      "\n",
      "  [[-1  3  2 -2  4]\n",
      "   [ 4 -1  3  4  5]\n",
      "   [ 4 -5  4  0  0]\n",
      "   [-3 -4 -3  3  3]]\n",
      "\n",
      "  [[ 0  4 -3 -4  6]\n",
      "   [-5  4 -5 -5  4]\n",
      "   [ 5 -4  1 -5 -2]\n",
      "   [-2 -4 -4 -5 -4]]]\n",
      "\n",
      "\n",
      " [[[ 4  0  2  4  5]\n",
      "   [ 4 -5  1  4  1]\n",
      "   [-5 -1 -1 -4  3]\n",
      "   [-1  3  0 -6  2]]\n",
      "\n",
      "  [[ 0  5  5 -4 -1]\n",
      "   [ 1  2  1  1  3]\n",
      "   [ 3 -6  1  6 -5]\n",
      "   [ 6  5 -5 -3  2]]\n",
      "\n",
      "  [[ 5 -4 -5 -4 -3]\n",
      "   [ 6  5  3 -6  3]\n",
      "   [ 2 -4  0  6  3]\n",
      "   [-1  1 -5  2  1]]]]\n",
      "----------\n",
      "----------\n",
      "[[[ 0  6  1 -4  0]\n",
      "  [-1  3  2 -2  4]\n",
      "  [ 0  4 -3 -4  6]]\n",
      "\n",
      " [[ 4  0  2  4  5]\n",
      "  [ 0  5  5 -4 -1]\n",
      "  [ 5 -4 -5 -4 -3]]]\n",
      "----------\n",
      "[[[ 0 -4 -5 -1 -5]\n",
      "  [ 4 -1  3  4  5]\n",
      "  [-5  4 -5 -5  4]]\n",
      "\n",
      " [[ 4 -5  1  4  1]\n",
      "  [ 1  2  1  1  3]\n",
      "  [ 6  5  3 -6  3]]]\n",
      "----------\n",
      "[[[ 6 -6 -5  0 -2]\n",
      "  [ 4 -5  4  0  0]\n",
      "  [ 5 -4  1 -5 -2]]\n",
      "\n",
      " [[-5 -1 -1 -4  3]\n",
      "  [ 3 -6  1  6 -5]\n",
      "  [ 2 -4  0  6  3]]]\n",
      "----------\n",
      "[[[ 6 -1  2 -6 -3]\n",
      "  [-3 -4 -3  3  3]\n",
      "  [-2 -4 -4 -5 -4]]\n",
      "\n",
      " [[-1  3  0 -6  2]\n",
      "  [ 6  5 -5 -3  2]\n",
      "  [-1  1 -5  2  1]]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(z.numpy(), end='\\n----------\\n----------\\n')\n",
    "for unst in tf.unstack(z, axis=2):\n",
    "    print(unst.numpy(), end='\\n----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  6  1 -4  0]\n",
      "   [ 0 -4 -5 -1 -5]\n",
      "   [ 6 -6 -5  0 -2]\n",
      "   [ 6 -1  2 -6 -3]]\n",
      "\n",
      "  [[-1  3  2 -2  4]\n",
      "   [ 4 -1  3  4  5]\n",
      "   [ 4 -5  4  0  0]\n",
      "   [-3 -4 -3  3  3]]\n",
      "\n",
      "  [[ 0  4 -3 -4  6]\n",
      "   [-5  4 -5 -5  4]\n",
      "   [ 5 -4  1 -5 -2]\n",
      "   [-2 -4 -4 -5 -4]]]\n",
      "\n",
      "\n",
      " [[[ 4  0  2  4  5]\n",
      "   [ 4 -5  1  4  1]\n",
      "   [-5 -1 -1 -4  3]\n",
      "   [-1  3  0 -6  2]]\n",
      "\n",
      "  [[ 0  5  5 -4 -1]\n",
      "   [ 1  2  1  1  3]\n",
      "   [ 3 -6  1  6 -5]\n",
      "   [ 6  5 -5 -3  2]]\n",
      "\n",
      "  [[ 5 -4 -5 -4 -3]\n",
      "   [ 6  5  3 -6  3]\n",
      "   [ 2 -4  0  6  3]\n",
      "   [-1  1 -5  2  1]]]]\n",
      "----------\n",
      "----------\n",
      "[[[ 0  0  6  6]\n",
      "  [-1  4  4 -3]\n",
      "  [ 0 -5  5 -2]]\n",
      "\n",
      " [[ 4  4 -5 -1]\n",
      "  [ 0  1  3  6]\n",
      "  [ 5  6  2 -1]]]\n",
      "----------\n",
      "[[[ 6 -4 -6 -1]\n",
      "  [ 3 -1 -5 -4]\n",
      "  [ 4  4 -4 -4]]\n",
      "\n",
      " [[ 0 -5 -1  3]\n",
      "  [ 5  2 -6  5]\n",
      "  [-4  5 -4  1]]]\n",
      "----------\n",
      "[[[ 1 -5 -5  2]\n",
      "  [ 2  3  4 -3]\n",
      "  [-3 -5  1 -4]]\n",
      "\n",
      " [[ 2  1 -1  0]\n",
      "  [ 5  1  1 -5]\n",
      "  [-5  3  0 -5]]]\n",
      "----------\n",
      "[[[-4 -1  0 -6]\n",
      "  [-2  4  0  3]\n",
      "  [-4 -5 -5 -5]]\n",
      "\n",
      " [[ 4  4 -4 -6]\n",
      "  [-4  1  6 -3]\n",
      "  [-4 -6  6  2]]]\n",
      "----------\n",
      "[[[ 0 -5 -2 -3]\n",
      "  [ 4  5  0  3]\n",
      "  [ 6  4 -2 -4]]\n",
      "\n",
      " [[ 5  1  3  2]\n",
      "  [-1  3 -5  2]\n",
      "  [-3  3  3  1]]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(z.numpy(), end='\\n----------\\n----------\\n')\n",
    "for unst in tf.unstack(z, axis=3):\n",
    "    print(unst.numpy(), end='\\n----------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Concat\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/concat).\n",
    "\n",
    "The idea here is to mash tensors together within one dimension, instead of packing (stacking) them into a higher one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[3 4 5]\n",
      "[6 7 8]\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.constant(np.arange(0,3), dtype=tf.int32)\n",
    "y2 = tf.constant(np.arange(3,6), dtype=tf.int32)\n",
    "y3 = tf.constant(np.arange(6,9), dtype=tf.int32)\n",
    "print(y1.numpy(), y2.numpy(), y3.numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "y = tf.concat([y1,y2,y3], axis=0)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21  -8 -19]\n",
      " [ 18   2  10]]\n",
      "\n",
      "[[  3  10  -2]\n",
      " [-17  13  -8]]\n",
      "\n",
      "[[ 20  10   5]\n",
      " [-15  -5  -9]]\n",
      "\n",
      "[[-21   0  -3]\n",
      " [-17  11   2]]\n"
     ]
    }
   ],
   "source": [
    "n1 = tf.cast(20*tf.get_variable('n', [2,3]), tf.int32)\n",
    "n2 = tf.cast(20*tf.get_variable('n', [2,3]), tf.int32)\n",
    "n3 = tf.cast(20*tf.get_variable('n', [2,3]), tf.int32)\n",
    "n4 = tf.cast(20*tf.get_variable('n', [2,3]), tf.int32)\n",
    "print(n1.numpy(), n2.numpy(), n3.numpy(), n4.numpy(), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21  -8 -19]\n",
      " [ 18   2  10]\n",
      " [  3  10  -2]\n",
      " [-17  13  -8]\n",
      " [ 20  10   5]\n",
      " [-15  -5  -9]\n",
      " [-21   0  -3]\n",
      " [-17  11   2]]\n"
     ]
    }
   ],
   "source": [
    "n = tf.concat([n1,n2,n3,n4], axis=0)\n",
    "print(n.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21  -8 -19   3  10  -2  20  10   5 -21   0  -3]\n",
      " [ 18   2  10 -17  13  -8 -15  -5  -9 -17  11   2]]\n"
     ]
    }
   ],
   "source": [
    "n = tf.concat([n1,n2,n3,n4], axis=1)\n",
    "print(n.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0 -12   7]\n",
      "  [  1  -1  -9  -7]\n",
      "  [ -8  11 -11  -6]]\n",
      "\n",
      " [[  0 -11   1  12]\n",
      "  [  8  -7 -10  -7]\n",
      "  [  9   0  -6  10]]]\n",
      "\n",
      "[[[ -5  -6   4  -9]\n",
      "  [ -2 -12  -1  -1]\n",
      "  [-13  10  -2   3]]\n",
      "\n",
      " [[ -9  -9 -12   2]\n",
      "  [-11   2  -6  -5]\n",
      "  [ -4  -3   3   7]]]\n"
     ]
    }
   ],
   "source": [
    "m1 = tf.cast(20*tf.get_variable('n', [2,3,4]), tf.int32)\n",
    "m2 = tf.cast(20*tf.get_variable('n', [2,3,4]), tf.int32)\n",
    "print(m1.numpy(), m2.numpy(), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0 -12   7]\n",
      "  [  1  -1  -9  -7]\n",
      "  [ -8  11 -11  -6]]\n",
      "\n",
      " [[  0 -11   1  12]\n",
      "  [  8  -7 -10  -7]\n",
      "  [  9   0  -6  10]]\n",
      "\n",
      " [[ -5  -6   4  -9]\n",
      "  [ -2 -12  -1  -1]\n",
      "  [-13  10  -2   3]]\n",
      "\n",
      " [[ -9  -9 -12   2]\n",
      "  [-11   2  -6  -5]\n",
      "  [ -4  -3   3   7]]]\n",
      "------------------------------\n",
      "[[[  0   0 -12   7]\n",
      "  [  1  -1  -9  -7]\n",
      "  [ -8  11 -11  -6]\n",
      "  [ -5  -6   4  -9]\n",
      "  [ -2 -12  -1  -1]\n",
      "  [-13  10  -2   3]]\n",
      "\n",
      " [[  0 -11   1  12]\n",
      "  [  8  -7 -10  -7]\n",
      "  [  9   0  -6  10]\n",
      "  [ -9  -9 -12   2]\n",
      "  [-11   2  -6  -5]\n",
      "  [ -4  -3   3   7]]]\n",
      "------------------------------\n",
      "[[[  0   0 -12   7  -5  -6   4  -9]\n",
      "  [  1  -1  -9  -7  -2 -12  -1  -1]\n",
      "  [ -8  11 -11  -6 -13  10  -2   3]]\n",
      "\n",
      " [[  0 -11   1  12  -9  -9 -12   2]\n",
      "  [  8  -7 -10  -7 -11   2  -6  -5]\n",
      "  [  9   0  -6  10  -4  -3   3   7]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.concat([m1,m2], axis=0).numpy()) # the external dimension now contains four tensors of shape 2x[3,4]\n",
    "print('-'*30)\n",
    "print(tf.concat([m1,m2], axis=1).numpy()) # the external dimension contains two tensors of shape [2x3,4] == [6,4]\n",
    "print('-'*30)\n",
    "print(tf.concat([m1,m2], axis=2).numpy()) # the external dimension contains two tensors of shape  [3,4*2] == [3,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Split\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/split).\n",
    "\n",
    "Difference with `unstack`, the dimensions are preserved. According to the [latter's doc](https://www.tensorflow.org/api_docs/python/tf/unstack):    \n",
    "> (Note that the dimension unpacked along is gone, unlike split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "z = tf.cast(\n",
    "            20*tf.get_variable(name='x',\n",
    "                               shape=[2,3,4,5]), \n",
    "            dtype=tf.int32)\n",
    "\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `unstack` we get a list of unpacked tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5)\n",
      "(3, 4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(unst.shape) for unst in tf.unstack(z, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically splits the outermost dimension (2). (The outer dim is preserved.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 4, 5)\n",
      "(1, 3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "for splt in tf.split(z, 2):\n",
    "    print(splt.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits dimension 1 (3) into one tensor with size one, another with two `[1,2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 4, 5)\n",
      "(2, 2, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "for splt in tf.split(z, [1,2], 1):\n",
    "    print(splt.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split along dimension 2, once into `[1,3]`, the other into two equal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 1, 5)\n",
      "(2, 3, 3, 5)\n",
      "\n",
      "(2, 3, 2, 5)\n",
      "(2, 3, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "for splt in tf.split(z, [1,3], 2):\n",
    "    print(splt.shape)\n",
    "print()\n",
    "for splt in tf.split(z, num_or_size_splits=2, axis=2):\n",
    "    print(splt.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 2)\n",
      "(2, 3, 4, 3)\n",
      "\n",
      "(2, 3, 4, 1)\n",
      "(2, 3, 4, 1)\n",
      "(2, 3, 4, 1)\n",
      "(2, 3, 4, 1)\n",
      "(2, 3, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "for splt in tf.split(z, [2,3], 3):\n",
    "    print(splt.shape)\n",
    "print()\n",
    "for splt in tf.split(z, num_or_size_splits=5, axis=3):\n",
    "    print(splt.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n",
      "---------\n",
      "[[[[ 0 -2  3  3  0]\n",
      "   [-3  6  0 -1 -1]\n",
      "   [ 0  0  0 -5  3]\n",
      "   [-5 -1  3 -3 -2]]\n",
      "\n",
      "  [[-3 -5 -4  0  1]\n",
      "   [ 3 -5  1  5  0]\n",
      "   [ 0  0  6 -1  0]\n",
      "   [ 0 -5  0 -6 -5]]\n",
      "\n",
      "  [[ 5 -4  0 -6  0]\n",
      "   [ 3 -3 -1  0 -3]\n",
      "   [ 1  2  4  4 -1]\n",
      "   [ 3  5 -3 -4 -4]]]\n",
      "\n",
      "\n",
      " [[[-3  5  2  1 -2]\n",
      "   [ 1  5  4  2  2]\n",
      "   [-2 -1 -4  0 -4]\n",
      "   [ 5  3  0  5 -4]]\n",
      "\n",
      "  [[-2  4  1 -2 -4]\n",
      "   [-5 -5 -5  3  3]\n",
      "   [-3  6 -1  5 -5]\n",
      "   [ 0  1 -6  0  2]]\n",
      "\n",
      "  [[ 4  4 -2 -5 -4]\n",
      "   [ 6  0 -2  3  6]\n",
      "   [-4 -6  2 -3  4]\n",
      "   [ 0 -4  6  0  1]]]]\n",
      "--------\n",
      "--------\n",
      "[[[[ 0 -2  3  3  0]\n",
      "   [-3  6  0 -1 -1]\n",
      "   [ 0  0  0 -5  3]\n",
      "   [-5 -1  3 -3 -2]]]\n",
      "\n",
      "\n",
      " [[[-3  5  2  1 -2]\n",
      "   [ 1  5  4  2  2]\n",
      "   [-2 -1 -4  0 -4]\n",
      "   [ 5  3  0  5 -4]]]]\n",
      "--------\n",
      "[[[[-3 -5 -4  0  1]\n",
      "   [ 3 -5  1  5  0]\n",
      "   [ 0  0  6 -1  0]\n",
      "   [ 0 -5  0 -6 -5]]\n",
      "\n",
      "  [[ 5 -4  0 -6  0]\n",
      "   [ 3 -3 -1  0 -3]\n",
      "   [ 1  2  4  4 -1]\n",
      "   [ 3  5 -3 -4 -4]]]\n",
      "\n",
      "\n",
      " [[[-2  4  1 -2 -4]\n",
      "   [-5 -5 -5  3  3]\n",
      "   [-3  6 -1  5 -5]\n",
      "   [ 0  1 -6  0  2]]\n",
      "\n",
      "  [[ 4  4 -2 -5 -4]\n",
      "   [ 6  0 -2  3  6]\n",
      "   [-4 -6  2 -3  4]\n",
      "   [ 0 -4  6  0  1]]]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "print(z.shape, end='\\n---------\\n')\n",
    "print(z.numpy(), end='\\n--------\\n--------\\n')\n",
    "for splt in tf.split(z, [1,2], 1): # split the next to outermost dimension into 1 & 2\n",
    "    print(splt.numpy(), end='\\n--------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n",
      "---------\n",
      "[[[[ 0 -2  3  3  0]\n",
      "   [-3  6  0 -1 -1]\n",
      "   [ 0  0  0 -5  3]\n",
      "   [-5 -1  3 -3 -2]]\n",
      "\n",
      "  [[-3 -5 -4  0  1]\n",
      "   [ 3 -5  1  5  0]\n",
      "   [ 0  0  6 -1  0]\n",
      "   [ 0 -5  0 -6 -5]]\n",
      "\n",
      "  [[ 5 -4  0 -6  0]\n",
      "   [ 3 -3 -1  0 -3]\n",
      "   [ 1  2  4  4 -1]\n",
      "   [ 3  5 -3 -4 -4]]]\n",
      "\n",
      "\n",
      " [[[-3  5  2  1 -2]\n",
      "   [ 1  5  4  2  2]\n",
      "   [-2 -1 -4  0 -4]\n",
      "   [ 5  3  0  5 -4]]\n",
      "\n",
      "  [[-2  4  1 -2 -4]\n",
      "   [-5 -5 -5  3  3]\n",
      "   [-3  6 -1  5 -5]\n",
      "   [ 0  1 -6  0  2]]\n",
      "\n",
      "  [[ 4  4 -2 -5 -4]\n",
      "   [ 6  0 -2  3  6]\n",
      "   [-4 -6  2 -3  4]\n",
      "   [ 0 -4  6  0  1]]]]\n",
      "--------\n",
      "--------\n",
      "[[[[ 0 -2  3  3  0]\n",
      "   [-3  6  0 -1 -1]]\n",
      "\n",
      "  [[-3 -5 -4  0  1]\n",
      "   [ 3 -5  1  5  0]]\n",
      "\n",
      "  [[ 5 -4  0 -6  0]\n",
      "   [ 3 -3 -1  0 -3]]]\n",
      "\n",
      "\n",
      " [[[-3  5  2  1 -2]\n",
      "   [ 1  5  4  2  2]]\n",
      "\n",
      "  [[-2  4  1 -2 -4]\n",
      "   [-5 -5 -5  3  3]]\n",
      "\n",
      "  [[ 4  4 -2 -5 -4]\n",
      "   [ 6  0 -2  3  6]]]]\n",
      "--------\n",
      "[[[[ 0  0  0 -5  3]\n",
      "   [-5 -1  3 -3 -2]]\n",
      "\n",
      "  [[ 0  0  6 -1  0]\n",
      "   [ 0 -5  0 -6 -5]]\n",
      "\n",
      "  [[ 1  2  4  4 -1]\n",
      "   [ 3  5 -3 -4 -4]]]\n",
      "\n",
      "\n",
      " [[[-2 -1 -4  0 -4]\n",
      "   [ 5  3  0  5 -4]]\n",
      "\n",
      "  [[-3  6 -1  5 -5]\n",
      "   [ 0  1 -6  0  2]]\n",
      "\n",
      "  [[-4 -6  2 -3  4]\n",
      "   [ 0 -4  6  0  1]]]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "print(z.shape, end='\\n---------\\n')\n",
    "print(z.numpy(), end='\\n--------\\n--------\\n')\n",
    "for splt in tf.split(z, num_or_size_splits=2, axis=2): # split the next to innermost dimension into shape [2,2]\n",
    "    print(splt.numpy(), end='\\n--------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n",
      "---------\n",
      "[[[[ 0 -2  3  3  0]\n",
      "   [-3  6  0 -1 -1]\n",
      "   [ 0  0  0 -5  3]\n",
      "   [-5 -1  3 -3 -2]]\n",
      "\n",
      "  [[-3 -5 -4  0  1]\n",
      "   [ 3 -5  1  5  0]\n",
      "   [ 0  0  6 -1  0]\n",
      "   [ 0 -5  0 -6 -5]]\n",
      "\n",
      "  [[ 5 -4  0 -6  0]\n",
      "   [ 3 -3 -1  0 -3]\n",
      "   [ 1  2  4  4 -1]\n",
      "   [ 3  5 -3 -4 -4]]]\n",
      "\n",
      "\n",
      " [[[-3  5  2  1 -2]\n",
      "   [ 1  5  4  2  2]\n",
      "   [-2 -1 -4  0 -4]\n",
      "   [ 5  3  0  5 -4]]\n",
      "\n",
      "  [[-2  4  1 -2 -4]\n",
      "   [-5 -5 -5  3  3]\n",
      "   [-3  6 -1  5 -5]\n",
      "   [ 0  1 -6  0  2]]\n",
      "\n",
      "  [[ 4  4 -2 -5 -4]\n",
      "   [ 6  0 -2  3  6]\n",
      "   [-4 -6  2 -3  4]\n",
      "   [ 0 -4  6  0  1]]]]\n",
      "--------\n",
      "--------\n",
      "[[[[ 0 -2]\n",
      "   [-3  6]\n",
      "   [ 0  0]\n",
      "   [-5 -1]]\n",
      "\n",
      "  [[-3 -5]\n",
      "   [ 3 -5]\n",
      "   [ 0  0]\n",
      "   [ 0 -5]]\n",
      "\n",
      "  [[ 5 -4]\n",
      "   [ 3 -3]\n",
      "   [ 1  2]\n",
      "   [ 3  5]]]\n",
      "\n",
      "\n",
      " [[[-3  5]\n",
      "   [ 1  5]\n",
      "   [-2 -1]\n",
      "   [ 5  3]]\n",
      "\n",
      "  [[-2  4]\n",
      "   [-5 -5]\n",
      "   [-3  6]\n",
      "   [ 0  1]]\n",
      "\n",
      "  [[ 4  4]\n",
      "   [ 6  0]\n",
      "   [-4 -6]\n",
      "   [ 0 -4]]]]\n",
      "--------\n",
      "[[[[ 3  3  0]\n",
      "   [ 0 -1 -1]\n",
      "   [ 0 -5  3]\n",
      "   [ 3 -3 -2]]\n",
      "\n",
      "  [[-4  0  1]\n",
      "   [ 1  5  0]\n",
      "   [ 6 -1  0]\n",
      "   [ 0 -6 -5]]\n",
      "\n",
      "  [[ 0 -6  0]\n",
      "   [-1  0 -3]\n",
      "   [ 4  4 -1]\n",
      "   [-3 -4 -4]]]\n",
      "\n",
      "\n",
      " [[[ 2  1 -2]\n",
      "   [ 4  2  2]\n",
      "   [-4  0 -4]\n",
      "   [ 0  5 -4]]\n",
      "\n",
      "  [[ 1 -2 -4]\n",
      "   [-5  3  3]\n",
      "   [-1  5 -5]\n",
      "   [-6  0  2]]\n",
      "\n",
      "  [[-2 -5 -4]\n",
      "   [-2  3  6]\n",
      "   [ 2 -3  4]\n",
      "   [ 6  0  1]]]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "print(z.shape, end='\\n---------\\n')\n",
    "print(z.numpy(), end='\\n--------\\n--------\\n')\n",
    "for splt in tf.split(z, [2,3], 3): # split the innermost dimension into shape [2,3]\n",
    "    print(splt.numpy(), end='\\n--------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Gather, Gather_nd\n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/gather) and [here](https://www.tensorflow.org/api_docs/python/tf/gather_nd).\n",
    "\n",
    "Two blog posts with examples [here](https://riptutorial.com/tensorflow/example/29018/extract-non-contiguous-slices-from-the-first-dimension-of-a-tensor) and [here](https://riptutorial.com/tensorflow/example/29069/how-to-use-tf-gather-nd).\n",
    "\n",
    "Tf.gather is built to access the innermost dimension of tensors (the indices as the last parameter are referring to that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "gth = tf.constant(np.arange(15), shape=[3,5])\n",
    "print(gth.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.gather(gth, [1]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also with a scalar, ergo no dimension around it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(tf.gather(gth, 0).numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.gather(gth, [1, 2]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduplications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.gather(gth, [0, 0, 0]).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with dimensions possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 2 3 4]\n",
      "  [0 1 2 3 4]]\n",
      "\n",
      " [[0 1 2 3 4]\n",
      "  [0 1 2 3 4]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.gather(gth, [[0,0],[0,0]]).numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3  4]\n",
      "   [ 0  1  2  3  4]]\n",
      "\n",
      "  [[ 0  1  2  3  4]\n",
      "   [ 0  1  2  3  4]]]\n",
      "\n",
      "\n",
      " [[[ 5  6  7  8  9]\n",
      "   [ 5  6  7  8  9]]\n",
      "\n",
      "  [[10 11 12 13 14]\n",
      "   [10 11 12 13 14]]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.gather(gth, [[[0,0],[0,0]],[[1,1],[2,2]]]).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now `gather_nd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]]\n",
      "\n",
      "3\n",
      "3\n",
      "\n",
      "[ 3  7 11]\n",
      "\n",
      "[0 1 2 3]\n",
      "\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [20 21 22 23]\n",
      " [20 21 22 23]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gth2 = tf.constant(np.arange(24), shape=[2,3,4])\n",
    "print(gth2.numpy())\n",
    "print()\n",
    "print(tf.gather_nd(gth2, [0,0,3]).numpy()) # identical to \n",
    "print(gth2[0][0][3].numpy())               # slicing!\n",
    "print()\n",
    "print(tf.gather_nd(gth2, [[0,0,3],[0,1,3],[0,2,3]]).numpy()) \n",
    "print()\n",
    "print(tf.gather_nd(gth2, [0,0]).numpy()) # similar to gather\n",
    "print()\n",
    "print(tf.gather_nd(gth2, [[0,0],[0,1],[1,2],[1,2]]).numpy()) # retrieve several rows, with repetition\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GPT-2-study-sample.ipynb',\n",
       " 'Normalization.ipynb',\n",
       " 'Shape_list_reduce_mean_max_splitting_merging_states_expanddims_convert_tile.ipynb',\n",
       " 'Gelu_plot.ipynb',\n",
       " 'the-annotated-transformer_14_0.png',\n",
       " 'Attention_mask.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'matrix-product-is-defined.jpg',\n",
       " 'GPT-2-study-encoder.ipynb',\n",
       " 'Conv1d.ipynb',\n",
       " 'Expand_tile_positions_fill_topk_oneszeroeslike_where_cond_while_multinomial_categorical.ipynb',\n",
       " 'Softmax.ipynb',\n",
       " 'Attention.ipynb',\n",
       " 'Transpose_stack_concat_split_gather.ipynb',\n",
       " 'ScatterNd1.png',\n",
       " 'batch_norm.png',\n",
       " 'Inspect_source.ipynb',\n",
       " 'the-annotated-transformer_33_0.png',\n",
       " 'matrix-multiplication.jpg',\n",
       " 'the-annotated-transformer_38_0.png',\n",
       " 'ScatterNd2.png']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TF Scatter_nd\n",
    "\n",
    "Not present in this code base, but the inverse operation of `tf.gather_nd`. Here [the documentation](https://www.tensorflow.org/api_docs/python/tf/scatter_nd).\n",
    "\n",
    "Nice pics on that page, couldn't resist...:\n",
    "\n",
    "![Scatter Nn1](ScatterNd1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 11  0 10  9  0  0 12]\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[4], [3], [1], [7]]) # where the elements will end up\n",
    "updates = tf.constant([9, 10, 11, 12]) # the elements to be inserted/scattered\n",
    "shape = tf.constant([8]) # shape of final tensor, will be initialized at zero\n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the docs, if the same index is used several times, addition ensues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 23  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[0], [0], [1], [1]])\n",
    "updates = tf.constant([9, 10, 11, 12]) \n",
    "shape = tf.constant([8]) \n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another try, add elements into 2d tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 10  0  0  0  0  0  0]\n",
      " [ 0 11  0 12  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[0,0], [0,1], [1,1], [1,3]])\n",
    "updates = tf.constant([9, 10, 11, 12]) \n",
    "shape = tf.constant([2,8]) \n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding slices:\n",
    "\n",
    "![Scatter Nn2](ScatterNd2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5 5 5 5]\n",
      "  [6 6 6 6]\n",
      "  [7 7 7 7]\n",
      "  [8 8 8 8]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[5 5 5 5]\n",
      "  [6 6 6 6]\n",
      "  [7 7 7 7]\n",
      "  [8 8 8 8]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[0], [2]]) \n",
    "updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]],\n",
    "                       [[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
    "shape = tf.constant([4, 4, 4])\n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adding functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10 10 10 10]\n",
      "  [12 12 12 12]\n",
      "  [14 14 14 14]\n",
      "  [16 16 16 16]]\n",
      "\n",
      " [[ 0  0  0  0]\n",
      "  [ 0  0  0  0]\n",
      "  [ 0  0  0  0]\n",
      "  [ 0  0  0  0]]]\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[0], [0]]) \n",
    "updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]],\n",
    "                       [[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
    "shape = tf.constant([2, 4, 4])\n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with slices, although complex-ish to think about. This time the first 2d tensor of `updates` gets distributed into the first rows of 2d tensors of `scatter`, while the second ends sprayed over the last rows.\n",
    "Remember:\n",
    "- the shape of `indices` must match `updates`: all elements of `updates` must be accounted for, and it's the position within `indices` that tells TF which element of `update` to treat next;\n",
    "- the content of each element of `indices` works like a slice, specifying a location within `scatter` (a slice or element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5 5 5 5]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [1 1 1 1]]\n",
      "\n",
      " [[6 6 6 6]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [2 2 2 2]]\n",
      "\n",
      " [[7 7 7 7]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [3 3 3 3]]\n",
      "\n",
      " [[8 8 8 8]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [4 4 4 4]]]\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[[0,0],[1,0],\n",
    "                        [2,0],[3,0]],\n",
    "                       [[0,3],[1,3],\n",
    "                        [2,3],[3,3]]]) \n",
    "updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]],\n",
    "                       [[1, 1, 1, 1], [2, 2, 2, 2],\n",
    "                       [3, 3, 3, 3], [4, 4, 4, 4]]])\n",
    "shape = tf.constant([4, 4, 4])\n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
